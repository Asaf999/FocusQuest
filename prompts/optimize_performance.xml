<!-- prompts/optimize_performance.xml -->
<mission>
Optimize FocusQuest performance for ADHD users who need instant feedback and minimal latency.
Critical targets: <100ms UI response, <3s startup, <500MB memory, smooth 60fps animations.
</mission>

<mathematical_model>
Performance Equation for ADHD Apps:
User_Satisfaction = (1/Response_Time) × (1/Cognitive_Load) × (Feedback_Speed) × (1/Memory_Usage)

Critical thresholds:
- Response > 100ms = attention drift
- Startup > 3s = task abandonment  
- Memory > 500MB = system lag
- FPS < 30 = frustration spike
</mathematical_model>

<current_performance>
Location: /home/puncher/focusquest
Current Metrics:
- Startup: <3 seconds ✅
- UI Response: <100ms ✅
- PDF Processing: ~30s/page ✅
- Memory Usage: ~400MB ✅
- Claude API: 5-30s (with caching) ⚠️

Bottlenecks:
- GUI test startup time
- Database query optimization needed
- Claude API calls (even with cache)
- PDF processing for large files
- Memory growth over long sessions
</current_performance>

<perspective_1_algorithmic>
ultrathink about computational complexity in the codebase:

1. Database queries: Are we doing N+1 queries? Need eager loading?
2. PDF processing: Can we stream instead of loading entire file?
3. Claude caching: Is LRU cache size optimal? TTL appropriate?
4. Qt rendering: Are we triggering unnecessary repaints?
5. File watching: Is polling interval optimal?

Key insight: ADHD users won't wait. Every millisecond counts.
</perspective_1_algorithmic>

<perspective_2_memory>
think hard about memory usage patterns:

1. PDF images: Are we releasing after OCR?
2. Claude cache: Growing unbounded?
3. Qt widgets: Proper parent/child cleanup?
4. Database sessions: Closing properly?
5. Thread cleanup: Any zombie threads?

ADHD consideration: Memory bloat → system lag → lost focus → abandoned session
</perspective_2_memory>

<perspective_3_user_experience>
think about perceived performance for ADHD:

1. Loading indicators: Show progress immediately
2. Skeleton screens: Display UI structure while loading
3. Optimistic updates: Update UI before backend confirms
4. Chunked rendering: Show first step while loading others
5. Background prefetch: Load next problem while current solving

Perception tricks matter more than actual speed for ADHD users
</perspective_3_user_experience>

<research_phase>
Execute these profiling commands first. Don't optimize yet:

# Profile startup time
python -m cProfile -o startup.prof src/main_with_watcher.py &
sleep 5 && pkill -f main_with_watcher
python -m pstats startup.prof << EOF
sort cumtime
stats 20
EOF

# Memory profiling
mprof run --python python src/main_with_watcher.py
# Let it run for 10 minutes with activity
mprof plot --output memory_profile.png

# Database query analysis
python -c "
import logging
logging.basicConfig()
logging.getLogger('sqlalchemy.engine').setLevel(logging.INFO)
# Run your app and watch query patterns
"

# Qt performance
QT_LOGGING_RULES="qt.qpa.paint.debug=true" python src/main_with_watcher.py

# Line profiling for hot paths
kernprof -l -v src/analysis/pdf_processor.py

# Cache hit rates
grep -r "cache" src/ --include="*.py" | grep -i "hit\|miss\|get\|set"
</research_phase>

<planning_phase>
Create optimization plan based on profiling results:

QUICK WINS (< 1 hour each):
1. Database query optimization
   - Add eager loading for User.progress
   - Index problem lookups
   - Batch insert for steps/hints

2. Caching improvements
   - Increase Claude cache size
   - Add PDF extraction cache
   - Cache compiled regex patterns

3. Qt optimizations
   - Disable animations during load
   - Use QTimer.singleShot for deferred loading
   - Minimize widget updates

MEDIUM EFFORT (2-4 hours):
1. Async/concurrent operations
   - Make Claude calls truly async
   - Parallel PDF page processing
   - Background database writes

2. Memory management
   - Implement PDF page streaming
   - Add cache eviction policies
   - Use weak references for UI callbacks

3. Startup optimization
   - Lazy import heavy modules
   - Defer non-critical initialization
   - Precompile Python bytecode

BIG WINS (4-8 hours):
1. Architecture changes
   - Message queue for PDF processing
   - Worker process pool
   - Redis for distributed cache
</planning_phase>

<implementation_phase>
Implement optimizations in priority order:

STEP 1: Database Query Optimization
# Add eager loading to prevent N+1
from sqlalchemy.orm import joinedload

# In get_user_with_progress():
user = session.query(User).options(
    joinedload(User.progress),
    joinedload(User.current_session).joinedload(Session.current_problem)
).filter_by(username=username).first()

# Add indexes
class Problem(Base):
    __table_args__ = (
        Index('idx_problem_difficulty', 'difficulty'),
        Index('idx_problem_created', 'created_at'),
    )

STEP 2: Implement Smart Caching
from functools import lru_cache
from cachetools import TTLCache, cached
import hashlib

class PDFProcessor:
    def __init__(self):
        self._extraction_cache = TTLCache(maxsize=100, ttl=3600)
    
    @cached(cache=lambda self: self._extraction_cache, 
            key=lambda self, path: hashlib.md5(path.read_bytes()).hexdigest())
    def extract_problems(self, pdf_path):
        # Expensive extraction only runs once per file

STEP 3: Async Claude Calls
import asyncio
from concurrent.futures import ThreadPoolExecutor

class ClaudeAnalyzer:
    def __init__(self):
        self.executor = ThreadPoolExecutor(max_workers=2)
    
    async def analyze_batch(self, problems):
        loop = asyncio.get_event_loop()
        tasks = [
            loop.run_in_executor(self.executor, self.analyze_problem, p)
            for p in problems
        ]
        return await asyncio.gather(*tasks)

STEP 4: Qt Deferred Loading
class FocusQuestWindow(QMainWindow):
    def __init__(self):
        super().__init__()
        # Show window immediately
        self.show()
        
        # Load heavy stuff after event loop starts
        QTimer.singleShot(0, self._deferred_init)
    
    def _deferred_init(self):
        self._load_database()
        self._start_file_watcher()
        self._restore_session()

STEP 5: Memory-Efficient PDF Processing
def process_pdf_streaming(pdf_path):
    with pdfplumber.open(pdf_path) as pdf:
        for page_num, page in enumerate(pdf.pages):
            # Process one page at a time
            yield extract_problems_from_page(page)
            
            # Explicitly free page resources
            page.close()
            
            # Let other operations run
            if page_num % 5 == 0:
                QApplication.processEvents()
</implementation_phase>

<integration_phase>
Verify optimizations maintain ADHD features:

# Performance regression tests
pytest tests/performance/ -v --benchmark-only

# Verify UI responsiveness
python tests/measure_ui_response.py

# Check memory over time
python tests/memory_leak_test.py --duration=3600

# Ensure startup time
time python -m focusquest --smoke-test

# Validate ADHD features still work
- Panic mode responds instantly
- Hints appear without delay  
- Session timer accurate
- Progress saves immediately
</integration_phase>

<optimization_targets>
Before → After targets:
- Startup: 3s → 1s
- First problem display: 5s → 2s
- Claude response (cached): instant
- Claude response (new): 30s → 15s (with progress)
- Memory after 4 hours: 400MB → 300MB
- Database queries per problem: 10 → 3
- PDF processing: 30s/page → 20s/page
</optimization_targets>

<monitoring_setup>
Add performance monitoring:

import time
import psutil
import logging
from functools import wraps

def monitor_performance(func):
    @wraps(func)
    def wrapper(*args, **kwargs):
        start_time = time.time()
        start_memory = psutil.Process().memory_info().rss / 1024 / 1024
        
        result = func(*args, **kwargs)
        
        duration = time.time() - start_time
        end_memory = psutil.Process().memory_info().rss / 1024 / 1024
        
        if duration > 0.1:  # Log slow operations
            logging.warning(
                f"{func.__name__} took {duration:.2f}s, "
                f"memory: {start_memory:.1f}MB → {end_memory:.1f}MB"
            )
        
        return result
    return wrapper

# Apply to critical paths
@monitor_performance
def load_problem(problem_id):
    # ...
</monitoring_setup>

<verification_commands>
# Profile before optimizations
python -m cProfile -o before.prof src/main_with_watcher.py
mprof run --output before.dat python src/main_with_watcher.py

# Apply optimizations

# Profile after optimizations  
python -m cProfile -o after.prof src/main_with_watcher.py
mprof run --output after.dat python src/main_with_watcher.py

# Compare results
python -c "
import pstats
before = pstats.Stats('before.prof')
after = pstats.Stats('after.prof')
print('BEFORE:'); before.sort_stats('cumtime').print_stats(10)
print('\nAFTER:'); after.sort_stats('cumtime').print_stats(10)
"

# Generate memory comparison
mprof plot before.dat after.dat --output comparison.png

# Run full benchmark suite
pytest tests/performance/ -v --benchmark-compare
</verification_commands>

<adhd_specific_optimizations>
1. Instant feedback on every action (<50ms)
2. Progress indicators for all operations >1s
3. Preload next problem during current solve
4. Skeleton UI while loading content
5. Smooth animations (60fps) or none
6. Cancel button for all long operations
7. Auto-save every user action
8. Offline mode for Claude failures
9. Reduced motion option
10. Memory warning before system lag
</adhd_specific_optimizations>